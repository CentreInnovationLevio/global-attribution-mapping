{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed-fico-biased.csv', index_col='Unnamed: 0') \n",
    "\n",
    "features = [x for x in df.columns.tolist() if x!='target']\n",
    "\n",
    "X = df[features].values\n",
    "y = df['target'].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6606, 37)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify 50-50 baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAREFUL**: each neural network session must be trained in a separate kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6606 samples, validate on 3255 samples\n",
      "Epoch 1/20\n",
      "6606/6606 [==============================] - 1s 100us/step - loss: 0.7322 - acc: 0.4873 - val_loss: 0.6934 - val_acc: 0.5346\n",
      "Epoch 2/20\n",
      "6606/6606 [==============================] - 0s 53us/step - loss: 0.6754 - acc: 0.6022 - val_loss: 0.6636 - val_acc: 0.6203\n",
      "Epoch 3/20\n",
      "6606/6606 [==============================] - 0s 51us/step - loss: 0.6507 - acc: 0.6606 - val_loss: 0.6445 - val_acc: 0.6642\n",
      "Epoch 4/20\n",
      "6606/6606 [==============================] - 0s 54us/step - loss: 0.6355 - acc: 0.6829 - val_loss: 0.6335 - val_acc: 0.6786\n",
      "Epoch 5/20\n",
      "6606/6606 [==============================] - 0s 53us/step - loss: 0.6251 - acc: 0.6954 - val_loss: 0.6257 - val_acc: 0.6854\n",
      "Epoch 6/20\n",
      "6606/6606 [==============================] - 0s 52us/step - loss: 0.6179 - acc: 0.6974 - val_loss: 0.6201 - val_acc: 0.6903\n",
      "Epoch 7/20\n",
      "6606/6606 [==============================] - 0s 55us/step - loss: 0.6123 - acc: 0.7018 - val_loss: 0.6155 - val_acc: 0.6906\n",
      "Epoch 8/20\n",
      "6606/6606 [==============================] - 0s 52us/step - loss: 0.6071 - acc: 0.7033 - val_loss: 0.6119 - val_acc: 0.6943\n",
      "Epoch 9/20\n",
      "6606/6606 [==============================] - 0s 54us/step - loss: 0.6030 - acc: 0.7054 - val_loss: 0.6085 - val_acc: 0.6971\n",
      "Epoch 10/20\n",
      "6606/6606 [==============================] - 0s 52us/step - loss: 0.5993 - acc: 0.7065 - val_loss: 0.6064 - val_acc: 0.6949\n",
      "Epoch 11/20\n",
      "6606/6606 [==============================] - 0s 48us/step - loss: 0.5962 - acc: 0.7056 - val_loss: 0.6042 - val_acc: 0.6971\n",
      "Epoch 12/20\n",
      "6606/6606 [==============================] - 0s 55us/step - loss: 0.5935 - acc: 0.7066 - val_loss: 0.6026 - val_acc: 0.6952\n",
      "Epoch 13/20\n",
      "6606/6606 [==============================] - 0s 53us/step - loss: 0.5913 - acc: 0.7075 - val_loss: 0.6015 - val_acc: 0.6934\n",
      "Epoch 14/20\n",
      "6606/6606 [==============================] - 0s 53us/step - loss: 0.5891 - acc: 0.7074 - val_loss: 0.6007 - val_acc: 0.6919\n",
      "Epoch 15/20\n",
      "6606/6606 [==============================] - 0s 55us/step - loss: 0.5869 - acc: 0.7097 - val_loss: 0.5996 - val_acc: 0.6931\n",
      "Epoch 16/20\n",
      "6606/6606 [==============================] - 0s 53us/step - loss: 0.5847 - acc: 0.7098 - val_loss: 0.6002 - val_acc: 0.6909\n",
      "Epoch 17/20\n",
      "6606/6606 [==============================] - 0s 52us/step - loss: 0.5831 - acc: 0.7116 - val_loss: 0.5986 - val_acc: 0.6925\n",
      "Epoch 18/20\n",
      "6606/6606 [==============================] - 0s 53us/step - loss: 0.5813 - acc: 0.7103 - val_loss: 0.5973 - val_acc: 0.6946\n",
      "Epoch 19/20\n",
      "6606/6606 [==============================] - 0s 54us/step - loss: 0.5799 - acc: 0.7115 - val_loss: 0.5963 - val_acc: 0.6937\n",
      "Epoch 20/20\n",
      "6606/6606 [==============================] - 0s 51us/step - loss: 0.5785 - acc: 0.7137 - val_loss: 0.5960 - val_acc: 0.6916\n",
      "[ 0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.          1.41213094  0.56368001\n",
      " -0.69342485 -0.1989281  -0.98479395  4.37759266  5.66269783  0.139438\n",
      " -0.42690737  1.95296539 -0.47317397 -0.75914541 -0.44117805 -0.2133518\n",
      " -0.18932772  0.25289243 -0.56247586 -0.36156169  0.99293128 -0.72899177\n",
      " -1.24673215]\n",
      "[[0.4997018]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.70300406 -0.09786655\n",
      " -0.69342485  0.86292711  1.581061   -0.4689605  -0.38690637  0.64926305\n",
      " -0.23022761  0.95163555  1.71639361 -0.87083907 -0.44117805  0.72336328\n",
      "  0.76515115 -0.65475899  1.30887129  0.6378851  -0.28255825 -0.72899177\n",
      " -1.0196856 ]\n",
      "[[0.5007641]]\n",
      "[ 0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.         -0.51264202  1.42162321\n",
      " -0.61204207  0.59746331 -0.71936068 -0.4689605  -0.38690637 -1.22009546\n",
      " -0.42690737  0.02733108  0.62160982  0.02271025 -0.44117805  1.19172081\n",
      "  1.24239058  1.9285566   1.45660922 -0.36156169 -0.28255825 -0.05816424\n",
      " -0.97427629]\n",
      "[[0.49944404]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.          0.09518102 -1.68971297\n",
      " -0.44927651 -0.16943212 -0.36544966 -0.4689605  -0.38690637  0.64926305\n",
      " -0.23022761 -0.20374504  0.07421793 -0.81499224 -0.44117805  0.72336328\n",
      "  0.76515115  1.26527287  0.12696783 -0.69471062 -0.28255825 -0.05816424\n",
      " -0.74722974]\n",
      "[[0.5006703]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.         -0.51264202 -0.66638313\n",
      "  2.96880019  1.39385471 -0.98479395 -0.4689605  -0.38690637  0.64926305\n",
      " -0.23022761 -0.97399876 -1.02056587 -0.81499224 -0.44117805 -0.2133518\n",
      " -0.18932772 -0.58493965 -1.89211726  0.30473617 -0.28255825  0.61266329\n",
      "  0.97832403]\n",
      "[[0.5009462]]\n",
      "[ 0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          1.\n",
      "  0.          0.          0.          0.         -1.22176889  0.65671\n",
      " -0.61204207  0.3319995  -0.45392741 -0.4689605  -0.38690637 -3.59927901\n",
      " -0.95138673  2.72321911  1.16900172  0.86041274 -0.20824681  0.25500574\n",
      "  0.28791171 -1.00385569 -0.95644368  0.30473617  0.99293128 -0.05816424\n",
      " -0.88345767]\n",
      "[[0.49974835]]\n",
      "[ 0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.         -0.91785737 -0.65604646\n",
      " -0.69342485  1.09889493  0.16541689 -0.4689605  -0.38690637 -3.08945396\n",
      "  1.27765055 -0.43482115 -0.47317397 -0.59160491 -0.44117805  0.72336328\n",
      "  0.28791171 -0.20093328  0.1762138  -0.02841276 -0.92030301 -0.05816424\n",
      " -0.29313664]\n",
      "[[0.5005595]]\n",
      "[ 0.          0.          0.          1.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.         -1.01916121  2.42427972\n",
      "  0.20178572  1.09889493 -0.63088293  1.95431608  0.621361    0.64926305\n",
      " -0.36134745  0.56650869 -1.02056587 -0.08898341 -0.44117805 -0.68170933\n",
      " -0.66656716  0.39253111 -1.94136323 -0.36156169  0.35518652 -0.72899177\n",
      " -1.06509491]\n",
      "[[0.50089973]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.         -0.61394586 -1.12119639\n",
      " -0.28651096  1.12839091 -1.07327171 -0.4689605  -0.38690637  0.30937969\n",
      " -0.23022761 -0.81994802 -0.47317397 -0.98253274 -0.44117805 -0.68170933\n",
      " -0.66656716 -1.00385569  0.1762138   0.6378851  -0.92030301  0.61266329\n",
      " -0.1114994 ]\n",
      "[[0.49927258]]\n",
      "[ 0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.         -1.82959193  1.33892989\n",
      " -0.36789374 -0.64136777 -1.07327171  0.33879836  0.621361    0.39435053\n",
      "  1.08097079  2.18404151  1.71639361  0.80456591 -0.20824681 -0.2133518\n",
      " -0.18932772  2.24274364 -0.16850804  0.97103403  0.99293128  1.28349082\n",
      "  0.8420961 ]\n",
      "[[0.4996263]]\n",
      "[ 1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.          1.10821942 -0.50099649\n",
      "  0.20178572 -0.34640799  0.43085016  0.33879836  0.621361    0.64926305\n",
      "  0.16313191  1.95296539 -1.02056587 -0.75914541 -0.44117805 -0.68170933\n",
      " -0.66656716  0.5321698  -2.6800529   0.30473617 -0.28255825 -0.72899177\n",
      " -0.1114994 ]\n",
      "[[0.50053185]]\n",
      "[ 0.          0.          0.          0.          1.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          1.          0.          0.         -0.2087305  -0.52166982\n",
      " -0.20512818 -1.08380745  0.78476119 -0.4689605  -0.38690637  0.64926305\n",
      " -0.23022761  0.7975848  -0.47317397 -0.42406441 -0.44117805 -0.68170933\n",
      " -0.66656716  0.77653749 -1.25191955  0.30473617  0.99293128 -0.72899177\n",
      " -0.1114994 ]\n",
      "[[0.5009435]]\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  1.          0.          0.          0.          0.          0.\n",
      "  0.          0.          1.          0.         -0.7152497   0.16055008\n",
      " -0.44927651 -0.46439191  0.69628343 -0.4689605  -0.38690637 -1.81489135\n",
      " -0.23022761  1.41378778  0.62160982 -0.31237074 -0.44117805  0.72336328\n",
      "  0.76515115 -0.55002998  0.6194276   1.30418296  1.63067604 -0.72899177\n",
      "  0.07013784]\n",
      "[[0.4992015]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train.shape[1] // 2,input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, y_test))\n",
    "    model.save('biased-data-model.h5')\n",
    "    \n",
    "    baseline_candidates = []\n",
    "\n",
    "    for x in X_train:\n",
    "        predicted = model.predict(np.array([x]))\n",
    "        if 0.499 < predicted < 0.501:\n",
    "            print(x)\n",
    "            print(predicted)\n",
    "            baseline_candidates.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first element produces .5002 output\n",
    "baseline = baseline_candidates[0]\n",
    "baseline = baseline.reshape(-1,1)\n",
    "#print(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate DeepLIFT Local Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DeepExplain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d1ba58195e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mDeepExplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mde\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biased-data-model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DeepExplain' is not defined"
     ]
    }
   ],
   "source": [
    "with DeepExplain(session=K.get_session()) as de:\n",
    "    # train\n",
    "    model = load_model('biased-data-model.h5')\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # explain\n",
    "    input_tensor = model.layers[0].input\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-1].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "    xs = X_train\n",
    "    ys = y_train\n",
    "    \n",
    "    baseline = baseline.squeeze()\n",
    "    deeplift_attributions = de.explain('deeplift', target_tensor * ys, input_tensor, xs, baseline=baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Integrated Gradients Local Attributions\n",
    "\n",
    "* Must restart Kernal to run (need a new context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with DeepExplain(session=K.get_session()) as de:\n",
    "    # train\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train.shape[1] // 2,input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # explain\n",
    "    input_tensor = model.layers[0].input\n",
    "    fModel = Model(inputs=input_tensor, outputs = model.layers[-1].output)\n",
    "    target_tensor = fModel(input_tensor)\n",
    "    \n",
    "    xs = X_train\n",
    "    ys = y_train\n",
    "    \n",
    "    intgrad_attributions = de.explain('intgrad', target_tensor * ys, input_tensor, xs, baseline=baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intgrad_attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Local Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_df = pd.DataFrame(deeplift_attributions, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intgrad_df = pd.DataFrame(intgrad_attributions, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplift_df.to_csv(\"data/deeplift_attributions-50-50-basline.csv\")\n",
    "intgrad_df.to_csv(\"data/intgrad_attributions-50-50-baseline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
